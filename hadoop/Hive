Install and Config
	config hadoop_home in hive-env.sh
	config mysql jdbc connection in hive-site.xml  https://www.edureka.co/blog/apache-hive-installation-on-ubuntu

	set hive debug modle: hive -hiveconf hive.root.logger=DEBUG,console

	init database
	schematool -dbType mysql -initSchema --verbose


Single user mode
Multi-user mode
Remote mode


CLI
	Change config value by:
		1). hive-site.xml
		2). hive --hiveconf property=value
		3). In hive CLI, set property=value


	hive -d col=id --database first
		select ${col} from firsttb;

	hive -e "select * from firstdb" --database firstdb;

	hive -f file.hql 
	hive -f hdfs://localhost:9000/user/file.hql  #use file in hdfs
	hive -i file.hql

	In CLI command:
		set
		set -v  #list all sets values
		reset
		add [FILE|JAR|ARCHIVE]
		list
		delete
		! <SHELL COMMAND>
		dfs <hdfs dfs COMMAND>
		QUERY


Beeline
	CLI of HiveServer2
	start hiveserver2
		1). hiveserver2
	Start beeline
		1). hive -service beeline
		2). beeline

	beeline> !connect jdbc:hive2://
		Issue#1: Error: Could not open client transport with JDBC Uri: jdbc:hive2://localhost:10000/default: Failed to open new session: java.lang.RuntimeException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.authorize.AuthorizationException): User: erzhang is not allowed to impersonate root (state=08S01,code=0)
		Resolution: 
		1). Add below config in core-site.xml for hadoop
		 <property>
    		<name>hadoop.proxyuser.root.hosts</name>
    		<value>*</value>
  		 </property>
  		 <property>
    		<name>hadoop.proxyuser.root.groups</name>
    		<value>*</value>
  		 </property>
  		 2). restart hadoop


Data Types
	TINYINT
	SMALLINT
	INT/INTEGER
	BIGINT
	FLOAT
	DOUBLE

	TIMESTAMP
	DATE

	STRING
	VARCHAR
	CHAR

	BOOLEAN
	BINARY

	ARRAY <TYPE>
	MAP
	STRUCT
	UNIONTYPE

	cast(value as type), cast a value to another type


Create Table
	Managed Table(Internal table, temp use only)

	External Table


desc formatted first;  #show table info


Data storage Types
	TextFile, default
	SequenceFile
	ORC
	PARQUET
	AVRO
	RCFILE

row format delimited
	fields terminated by ','
	stored as TEXTFILE
	Location '/';

row format serde
	'Regex'/'JSON'/'CSV/TSV'
	stored as TEXTFILE


Partition Table
	partitioned by (par_col par_type)
	static and dynamic partition (set hive.exec.dynamic.partition=true)
	mode: strict/nonstrict
	clustered by
	sort by
	distributed by

Bucket(Bucketed Sorted Tables)

Skewed Tables

Temporary Tables

DROP TABLE [IF EXISTS TABLE_NAME [PURGE];
TRUNCATE TABLE TABLE_NAME[PARTITION partition_spec];














